# to be copied to
# GalaxyKickStart/roles/galaxyprojectdotorg.galaxy-extras/templates/configure_slurm.py.j2
from socket import gethostname
from string import Template
from os import environ
import subprocess


SLURM_CONFIG_TEMPLATE = '''
# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=$control_machine
#ControlAddr=
#BackupController=
#BackupAddr=
#
AuthType=auth/munge
CacheGroups=0
#CheckpointType=checkpoint/none
CryptoType=crypto/munge
MpiDefault=none
#PluginDir=
#PlugStackConfig=
#PrivateData=jobs
ProctrackType=proctrack/pgid
#Prolog=
#PrologSlurmctld=
#PropagatePrioProcess=0
#PropagateResourceLimits=
#PropagateResourceLimitsExcept=
ReturnToService=1
#SallocDefaultCommand=
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/tmp/slurmd
SlurmUser=$user
#SlurmdUser=root
#SrunEpilog=
#SrunProlog=
StateSaveLocation=/tmp/slurm
SwitchType=switch/none
#TaskEpilog=
TaskPlugin=task/none
#TaskPluginParam=
#TaskProlog=
InactiveLimit=0
KillWait=30
MinJobAge=300
#OverTimeLimit=0
SlurmctldTimeout=120
SlurmdTimeout=300
#UnkillableStepTimeout=60
#VSizeFactor=0
Waittime=0
FastSchedule=1
SchedulerType=sched/backfill
SchedulerPort=7321
SelectType=select/cons_res
SelectTypeParameters=CR_CPU_Memory
AccountingStorageType=accounting_storage/none
#AccountingStorageUser=
AccountingStoreJobComment=YES
ClusterName=$cluster_name
#DebugFlags=
#JobCompHost=
#JobCompLoc=
#JobCompPass=
#JobCompPort=
JobCompType=jobcomp/none
#JobCompUser=
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/none
SlurmctldDebug=3
#SlurmctldLogFile=
SlurmdDebug=3
#SlurmdLogFile=
NodeName=$hostname CPUs=$cpus RealMemory=$memory State=UNKNOWN
PartitionName=$partition_name Nodes=$hostname Default=YES MaxTime=INFINITE State=UP Shared=FORCE DefMemPerCPU=$mem_per_cpu
'''
slurm_status = subprocess.check_output(['slurmd', '-C'])
cpus = slurm_status.split("CPUs=")[1].split(" Boards")[0]
memory = slurm_status.split("RealMemory=")[1].split(" TmpDisk")[0]
mem_per_cpu = int(memory) / int(cpus)

def main():
    hostname = gethostname()
    template_params = {
        "hostname": hostname,
        "control_machine": environ.get('SLURM_CONTROL_MACHINE', hostname),
        "cluster_name": environ.get('SLURM_CLUSTER_NAME', 'cluster'),
        "user": environ.get('SLURM_USER_NAME', 'galaxy'),
        "partition_name": environ.get('SLURM_PARTITION_NAME', 'debug'),
        "cpus": environ.get("SLURM_CPUS", cpus),
        "memory": environ.get("SLURM_MEMORY", memory),
        "mem_per_cpu": environ.get("SLURM_MEMORY_PER_CPU", int(memory)/int(cpus))
    }
    config_contents = Template(SLURM_CONFIG_TEMPLATE).substitute(template_params)
    open("/etc/slurm-llnl/slurm.conf", "w").write(config_contents)

if __name__ == "__main__":
    main()
